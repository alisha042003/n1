# -*- coding: utf-8 -*-
"""Copy of 2.Implementation of Classification using ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZlWP1IFQRufUAjkeuHc3P621XtaveSOY
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score,confusion_matrix
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

df = pd.read_csv('Churn_Modelling.csv')
df.head()

df.drop(columns=['RowNumber','CustomerId','Surname'],axis='columns',inplace=True)
df.head()

df.shape

df.Gender.value_counts()

df.Geography.value_counts()

df.Exited.value_counts()

data = pd.get_dummies(df,columns=["Geography","Gender"], dtype=int, drop_first=True)
data.head()

X = data.drop(['Exited'],axis='columns')
y = data['Exited']

X.shape

x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

x_train.shape

y_train.shape

Scaler = StandardScaler()
x_train = Scaler.fit_transform(x_train)
x_test = Scaler.transform(x_test)

model = Sequential()
model.add(Dense(units=3,activation='relu',input_dim=11))
model.add(Dense(units=2,activation='relu'))
model.add(Dense(units=1,activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.layers[0].get_weights()

model.fit(x_train,y_train,epochs=10)

y_pred = model.predict(x_test)

#y_pred = y_pred.argmax(axis=-1)
accuracy_score(y_test,y_pred.round())

